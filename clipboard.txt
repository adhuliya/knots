
https://www.musictheory.net/exercises

https://www.fullstackpython.com/bottle.html

$ django-admin startproject mysite

$ python manage.py runserver 0:8000

Let’s look at what startproject created:

mysite/
    manage.py
    mysite/
        __init__.py
        settings.py
        urls.py
        asgi.py
        wsgi.py



$ python manage.py runserver

$ python manage.py startapp polls

That’ll create a directory polls, which is laid out like this:

polls/
    __init__.py
    admin.py
    apps.py
    migrations/
        __init__.py
    models.py
    tests.py
    views.py



$ python manage.py makemigrations polls

$ python manage.py sqlmigrate polls 0001

If you’re interested, you can also run python manage.py check; this checks for any problems in your project without making migrations or touching the database.

$ python manage.py migrate

We can examine the machine instructions emitted in this step by calling llc with the -print-machineinstrs flag and looking at the first output that says "After instruction selection":

By passing -show-mc-inst and -show-mc-encoding to llc, we can see the MC-level instructions it creates with their encoding, alongside the actual assembly code:

/// This is the main entry point for the type legalizer. This does a top-down
/// traversal of the dag, legalizing types as it goes. Returns "true" if it made
/// any changes.
bool DAGTypeLegalizer::run() {
  bool Changed = false;


 The various operation node types are described at the top of the include/llvm/CodeGen/ISDOpcodes.h file.

 Because nodes may define multiple values, edges are represented by instances of the SDValue class, which is a <SDNode, unsigned> pair, indicating the node and result value being used, respectively. Each value produced by an SDNode has an associated MVT (Machine Value Type) indicating what the type of the value is.

https://llvm.org/docs/CodeGenerator.html#introduction-to-selectiondags

QQ thinkpad self diagnostic beeps how to manage?


QQ How to detect which process just started/stopped?

QQ How to see a history of processes that exited in order?

http://localhost:5050/knotes-git/sparc/sparc.html#llvm



Cambridge Assessment English
https://www.cambridgeenglish.org/exams-and-tests/cefr/
Common European Framework of Reference for Languages (CEFR)

word: 'ruddy' is the euphemism of 'bloody'

gcc -E -nostdinc will bypass standard #include files
You might also need to specify -x c if the file you are processing has not a standard c extension

QQ Is Intraprocedural and Context Insensitive the same?

PP. ((x - K_2) \union G_2) \intersect ((x - K_1) \union G_1)
    (x - (K_1 \union K_2)) \union (G_1 \intersect G_2)


Happening now video meeting 
QQ How to disable internet on ubuntu?
QQ How to disable copy paste on ubuntu?
sudo ip link set wlp5s0 down
https://unix.stackexchange.com/questions/213840/how-to-toggle-or-turn-off-text-selection-being-sent-to-the-clipboard
spelling: broccoli, bouquet, mnemonic
spelling: insist
spelling: imitate
spelling: omitted
spelling: capillary
spelling: remuneration

ROHAN NAIR & HIMANSHU SHAH emails
  rohan.nair@somaiya.edu
  himanshu.ss@somaiya.edu

spelling: immediately
TODO: Optimize images for website?


Once upon a time in a jungle, deers lived a care free life.
One day, a pride of lions ventured into the jungle, to everyone's surprise.

All deers hid to starve the lions to death!
But some deers had not seen the pride and they were laughing at the rest.
They enticed other deers with fresh field grass where the danger most lied,
only to be eaten by the lions once in a while...

The lions survived on the ignorants...
And careful deers were frustated by their predicaments.
The deers began to miss the nourishing grass on the fields,
and all the fun they had when the nature was their shield.

The wait seems too long... the lions survived...
The deers lived, but their fresh grass livelihoods died
The grass in the hidden corners of the jungle was running out fast...
The deers had no choice left at last...

The lions didn't die, but the deers stepped out...
They had watched the hunting of the ignorants,
and some accidents of the passed outs.
Lessons learned...
The deers ate on large grasslands,
where the lions had no choice but to be clearly seen on the plain lands.
The deers ran when lions came,
but some slipped and died lame...

Now the lions were a part of life,
and the deers survived,
and the deers survived.


# Related Work notes:
From Lerner's paper:
A number of analysis frameworks have been developed for
making intra- and inter-procedural analyses easier to write
and reason about, includeing Sharlit[27], SPARE [28],
FIAT [17], McCAT [19], System-Z [34], PAG[2], the k-tuple
dataflow analysis framework [23], and Dwyer and Clarke's
system [15]. However, none of these systems address integrating
transformations with analyses, nor automatically
combining analyses profitably.

Manual methods:

Nelson and Oppen [24] - describe how under certain conditions
  satisfiability programs for several theories can be combined into
  a satisfiability program for the combined theory.
Click and Cooper [9] - defines formally the circumstances in which two
  dataflow analyses should be integrated to reach better fixed points than
  repeated sequences of the two analyses run separately.
Cousot and Cousot[11] - also point out that such interactions can arise.

Whitfield and Soffa [32, 33] - examins interactions between different optimizations.

Assmann [3,4]


Bronevetsky and Anantkrishnan:
Abstract Transitioning System
Loose composition - e.g. LLVM
Tight composition - e.g. Wegman.., Click.., Lerner.., Nelson..


#python3
from inspect import currentframe, getframeinfo

frameinfo = getframeinfo(currentframe())

print(frameinfo.filename, frameinfo.lineno)


Count: 643, Func: f:LBM_initializeSpecialCellsForLDC
Count: 533, Func: f:LBM_initializeSpecialCellsForLDC

Count: 20, Func: f:loadValue
Count: 17, Func: f:loadValue
http://isola-conference.org/isola2020/
If you know the commit you want to return to is the head of some branch, or is tagged, then you can just

git checkout branchname

You can also use git reflog to see what other commits your HEAD (or any other ref) has pointed to in the past.
git log --all (or more usefully, git log --oneline --graph --all). 

brighness setting in /etc/X11/xorg.conf see link below it worked for me
https://askubuntu.com/a/1060843/777713

https://docs.docker.com/config/containers/runmetrics/


// Define prefix increment operator.
Point& Point::operator++()
{
   _x++;
   _y++;
   return *this;
}

// Define postfix increment operator.
Point Point::operator++(int)
{
   Point temp = *this;
   ++*this;
   return temp;
}
pypy manage.py test
 Not all libraries are compatible with PyPy.
I use pypy+ gunicorn + django + nginx and it works like a charm.
https://stackoverflow.com/questions/16333306/drawbacks-to-running-django-under-pypy
Gyorgy Orban and Gabor Horvath
https://github.com/Ericsson/codechecker/tree/master/tools/report-converter
https://github.com/Ericsson/codechecker/blob/cbb18d904a510d1d6457fa5355ea5543e33f537f/web/server/tests/unit/plist_test_files/clang-5.0-trunk.plist
3

Additional arguments can be passed to LLVM's option parser with -mllvm. For your scenario this would look something like this:

clang [...] -mllvm -print-after-all


QQ. How does the diff algo work?


Clang AST Matcher API and FixIt API
---------------------------------------

https://devblogs.microsoft.com/cppblog/exploring-clang-tooling-part-1-extending-clang-tidy/
https://devblogs.microsoft.com/cppblog/exploring-clang-tooling-part-2-examining-the-clang-ast-with-clang-query/
https://devblogs.microsoft.com/cppblog/exploring-clang-tooling-part-3-rewriting-code-with-clang-tidy/
http://clang.llvm.org/docs/LibASTMatchersReference.html




95 104 12 123 134

The equation (A) is only needed if an analysis is non-monotone.
A monotone analysis with or without (A) will always yield an MFP solution.
A non-monotone analysis without (A) may never terminate,
so my guess is a "different" result would be a non-terminating computation.
Is my understanding correct?
Resource

‘resource’ module for finding the current (Resident) memory consumption of your program

[Resident memory is the actual RAM your program is using]

>>> import resource

>>> resource.getrusage(resource.RUSAGE_SELF).ru_maxrss

4332
https://dart.dev/samples
https://dart.dev/guides/language/language-tour
dict = 'something awful'  # Bad Idea... pylint: disable=redefined-builtin
pylint3 --disable=R,C,W span |& tee pylint3.out 
 pylint3 --disable=C0330 span |& tee pylint3.out                                         [±master ●●]


LTO pass in LLVM
http://lists.llvm.org/pipermail/llvm-dev/2017-August/116172.html

CIL-PROJECT

https://people.eecs.berkeley.edu/~necula/cil/merger.html
https://github.com/cil-project/cil

The following command generates `main.o` and `lib.o` which are
C files with all the preprocessing done.

    cilly --merge --keepmerged --verbose --gcc=clang -I. -c main.c lib.c

    cilly --merge --keepmerged --gcc=clang main.o lib.o

The last command above generates a `a.out_comb.c` file with whole
of C source combined.

Using `find` command:
find -name "testing.*" -print0 | xargs -0 wc -l
see the examples in `man find`.


Docker Commands:
cat init_setup.sql| docker exec -i postgres psql -U postgres
docker exec -it postgres /bin/bas
docker logs postgres 
docker container ls --all
docker ps --all
docker container rm $(docker ps -aq)
docker ps -aq
docker image ls   
docker logs mysite 
docker image rm prostgres:13.0
docker container rm --force `cat tmp.del`
docker container ls --all > tmp.del 
docker container rm *
docker build --tag prostgres:13.0 . 
sudo service docker restart    
docker exec -it mysite /bin/bash 
docker volume ls 
docker inspect postgres  
docker network create itsoflife
docker network ls
docker build --tag mysite:1.0        
 docker rm --force mysite  

https://dart.dev/codelabs/dart-cheatsheet
https://dart.dev/samples

​
https://conf.researchr.org/home/pldi-2021

The log for this run is in /home/codeman/.itsoflife/mydata/local/tmp/SPEC-CPU2006/cpu2006_install/result/CPU2006.002.log

runspec --config=span-linux-ia64-cilly --size=ref --noreportable --tune=base --iterations=1 bzip2  
runspec --config=span-linux-ia64-cilly --size=ref --noreportable --tune=base --iterations=1 bzip2 
runspec --config=span-linux-ia64-cilly --action=build --tune=base bzip2


https://www.digitalocean.com/community/tutorials/how-to-use-systemctl-to-manage-systemd-services-and-units

systemd
=================
In systemd, the target of most actions are “units”, which are resources that systemd knows how to manage. Units are categorized by the type of resource they represent and they are defined with files known as unit files. The type of each unit can be inferred from the suffix on the end of the file.
sudo systemctl start application.service
sudo systemctl stop application.service
sudo systemctl restart application.service
sudo systemctl reload application.service
sudo systemctl reload-or-restart application.service
sudo systemctl enable application.service
sudo systemctl disable application.service
systemctl status application.service
systemctl is-active application.service
systemctl is-enabled application.service
systemctl is-failed application.service
systemctl list-units # lists all active units
systemctl list-units --all
systemctl list-units --all --state=inactive
systemctl list-units --type=service
systemctl list-unit-files
Displaying a Unit File
systemctl cat atd.service
Displaying Dependencies
systemctl list-dependencies sshd.service
Checking Unit Properties
systemctl show sshd.service

https://askubuntu.com/questions/801404/bluetooth-connection-failed-blueman-bluez-errors-dbusfailederror-protocol-no
sudo apt-get install pulseaudio-module-bluetooth
pactl load-module module-bluetooth-discover

https://developer.ibm.com/technologies/linux/series/learn-linux-101/

Deploying container to google cloud run:
REF: https://cloud.google.com/run/docs/quickstarts/build-and-deploy
Connecting to postgre sql instance:
https://cloud.google.com/sql/docs/postgres/connect-run
Testing the Container Image Locally:
https://cloud.google.com/run/docs/testing/local
Cloud Storage Client Libraries:
https://cloud.google.com/storage/docs/reference/libraries

Create a bucket for static files:

    gsutil mb gs://<your-bucket-name>
    gsutil defacl set public-read gs://<your-bucket-name>
    gsutil -m rsync -r ./static gs://<your-bucket-name>/static

URL: https://storage.googleapis.com/<your-bucket-name>/static/...

https://cloud.google.com/storage/docs/hosting-static-website#gcloud
+ GIT_OPTIONAL_LOCKS=0 command timeout 1s git "$@"
https://stackoverflow.com/questions/21889053/what-is-the-runtime-performance-cost-of-a-docker-container
The exception to this is Docker’s NAT — if you use port mapping (e.g., docker run -p 8080:8080), then you can expect a minor hit in latency, as shown below. However, you can now use the host network stack (e.g., docker run --net=host) when launching a Docker container, which will perform identically to the Native column (as shown in the Redis latency results lower down). 
from itertools import chain
slots = chain.from_iterable(getattr(cls, '__slots__', []) for cls in B.__mro__)


CREATE DATABASE database_name
WITH
   [OWNER =  role_name]
   [TEMPLATE = template]
   [ENCODING = encoding] 'UTF8'
   [LC_COLLATE = collate]
   [LC_CTYPE = ctype]
   [TABLESPACE = tablespace_name]
   [ALLOW_CONNECTIONS = true | false] true
   [CONNECTION LIMIT = max_concurrent_connection]
   [IS_TEMPLATE = true | false ] false

SELECT
    pg_size_pretty (pg_relation_size('actor'));
SELECT
    pg_size_pretty (
        pg_total_relation_size ('actor')
    );
SELECT
    pg_size_pretty (
        pg_database_size ('dvdrental')
    );
SELECT
    pg_size_pretty (pg_indexes_size('actor'));
SELECT
    pg_size_pretty (
        pg_tablespace_size ('pg_default')
    );
select pg_column_size(5::smallint);
select pg_column_size(5::int);
select pg_column_size(5::bigint);

Python encript a string/byte array:

>>> from cryptography.fernet import Fernet
>>> key = Fernet.generate_key() # save this key for future use
>>> f = Fernet(key)
>>> token = f.encrypt(b"my deep dark secret")
>>> token
b'...'
>>> f.decrypt(token)
b'my deep dark secret'


See this too:
https://stackoverflow.com/a/59835994/2369985

    import secrets
    from cryptography.hazmat.primitives.ciphers.aead import AESGCM
    
    # Generate a random secret key (AES256 needs 32 bytes)
    key = secrets.token_bytes(32)
    
    # Encrypt a message
    nonce = secrets.token_bytes(12)  # GCM mode needs 12 fresh bytes every time
    ciphertext = nonce + AESGCM(key).encrypt(nonce, b"Message", b"")
    
    # Decrypt (raises InvalidTag if using wrong key or corrupted ciphertext)
    msg = AESGCM(key).decrypt(ciphertext[:12], ciphertext[12:], b"")

Even with the same key and the same message, the ciphertext will always be completely different (because of a different nonce). Do note that ciphertext is always exactly 28 bytes longer than the message, so if the message length needs to be hidden, you could pad all messages to same length before encryption.


I see that the docker image doesn't contain any AJIT related stuff. To test it we need to build the buildroot inside the docker container to be sure that we are building the correct docker image (hopefully with some tests added)
git ls-files -i --exclude-from=.gitignore | xargs git rm --cached  

https://lebkowski.name/docker-volumes/
git rm --cached `git ls-files -i --exclude-from=.gitignore`
We will provide two types of key lengths: 128 and 256, selected at initdb time, e.g. --encrypt-aes128. 
Build successes: 433.milc(base)

Build successes: 445.gobmk(base)

Build successes: 429.mcf(base)

Build successes: 458.sjeng(base)

Build successes: 470.lbm(base)
Build successes: 470.lbm(base)

